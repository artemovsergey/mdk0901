# Лекция для студентов: Контейнеризация в .NET-разработке: Docker и Docker Compose на примере приложения с PostgreSQL

**Цель:** Дать понимание принципов контейнеризации, научить создавать Docker-образы для .NET-приложений, управлять многоконтейнерными приложениями с помощью Docker Compose и работать с PostgreSQL в контейнере.

---

### **План лекции:**

1.  **Введение в контейнеризацию:** Зачем это нужно? Проблемы, которые решает Docker.
2.  **Ключевые концепции Docker:** Образы, Контейнеры, Dockerfile, Docker Daemon.
3.  **Docker на практике: Контейнеризация .NET-приложения:**
    *   Создание простого ASP.NET Core Web API.
    *   Написание Dockerfile.
    *   Построение образа и запуск контейнера.
4.  **Работа с данными: PostgreSQL в Docker:**
    *   Запуск официального образа PostgreSQL.
    *   Подключение к контейнеру с БД.
    *   Понимание томов (Volumes) для сохранения данных.
5.  **Оркестрация многоконтейнерных приложений: Docker Compose:**
    *   Что такое Docker Compose и зачем он нужен?
    *   Создание `docker-compose.yml` файла.
    *   Запуск и управление всем стеком (API + БД) одной командой.
6.  **Резюме**
7.  **Контрольные вопросы**

---

### **Подробное рассмотрение каждого пункта плана:**

#### **1. Введение в контейнеризацию**

**Проблема:** "У меня на машине работает, а на сервере — нет!".
Разработчики сталкиваются с различиями в окружениях: версии ОС, установленные библиотеки, настройки сети, версии .NET SDK и т.д.

**Решение — Контейнеризация.** Это технология упаковки приложения и всех его зависимостей (библиотек, системных утилит, кода, настроек) в изолированную, переносимую единицу — **контейнер**.

**Аналогия:**
*   **Виртуальная машина** — виртуализирует *целую операционную систему* (Гость) поверх основной (Хост). Тяжеловесна, требует много ресурсов.
*   **Контейнер** — виртуализирует *пользовательское пространство* (файлы, процессы, сеть). Все контейнеры разделяют ядро хостовой ОС. Легковесны и быстры.

**Преимущества Docker:**
*   **Консистентность:** Одинаковое поведение на всех этапах (dev, test, prod).
*   **Изоляция:** Приложение в контейнере не влияет на хост-систему и другие контейнеры.
*   **Переносимость:** Собранный образ можно запустить anywhere, где есть Docker.
*   **Масштабируемость:** Легко запустить несколько копий приложения.

---

#### **2. Ключевые концепции Docker**

*   **Docker Image (Образ):** Шаблон только для чтения, используемый для создания контейнеров. Содержит код, среду выполнения, библиотеки и переменные окружения. Например, образ `mcr.microsoft.com/dotnet/aspnet:8.0` содержит среду выполнения .NET 8.
*   **Docker Container (Контейнер):** Запущенный экземпляр образа. Это изолированный процесс в операционной системе. Контейнеры можно запускать, останавливать, удалять.
*   **Dockerfile:** Текстовый файл с инструкциями по сборке образа. Это "рецепт" вашего приложения.
*   **Docker Daemon (Демон):** Фоновая служба, которая управляет образами, контейнерами, сетями и томами.

---

#### **3. Docker на практике: Контейнеризация .NET-приложения**

**Шаг 1: Создаем простое ASP.NET Core Web API**
```bash
dotnet new webapi -n MyDockerApi
cd MyDockerApi
```
Убедитесь, что приложение работает: `dotnet run`.

**Шаг 2: Пишем Dockerfile**

Создайте в корне проекта файл с именем `Dockerfile` (без расширения).

```dockerfile
# 1. Этап сборки (Build Stage)
# Используем официальный образ SDK для компиляции приложения
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
WORKDIR /src

# Копируем файлы проекта и восстанавливаем зависимости
COPY ["MyDockerApi.csproj", "."]
RUN dotnet restore "MyDockerApi.csproj"

# Копируем весь исходный код и собираем приложение
COPY . .
RUN dotnet build "MyDockerApi.csproj" -c Release -o /app/build
RUN dotnet publish "MyDockerApi.csproj" -c Release -o /app/publish

# 2. Этап финального образа (Runtime Stage)
# Используем маленький образ только со средой выполнения (без SDK)
FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS final
WORKDIR /app

# Копируем собранное приложение из этапа сборки
COPY --from=build /app/publish .

# Открываем порт, который слушает наше приложение (обычно 8080 для .NET в контейнере)
EXPOSE 8080

# Команда для запуска приложения при старте контейнера
ENTRYPOINT ["dotnet", "MyDockerApi.dll"]
```

**Пояснение к инструкциям:**
*   `FROM`: Задает базовый образ.
*   `WORKDIR`: Устанавливает рабочую директорию внутри контейнера.
*   `COPY`: Копирует файлы с хоста в образ.
*   `RUN`: Выполняет команду во время сборки образа.
*   `EXPOSE`: Информирует Docker, что контейнер слушает на указанном порту.
*   `ENTRYPOINT`: Команда, которая запускается при старте контейнера.

**Шаг 3: Сборка образа и запуск контейнера**

```bash
# Собираем образ с тегом 'my-docker-api'
docker build -t my-docker-api .

# Запускаем контейнер из образа
# -p 5000:8080: пробрасываем порт 5000 хоста на порт 8080 контейнера.
docker run -d -p 5000:8080 --name my-running-app my-docker-api
```

Теперь ваше API доступно по адресу `http://localhost:5000/weatherforecast`.

---

#### **4. Работа с данными: PostgreSQL в Docker**

Базы данных — это stateful-сервисы (сохраняют состояние). Нам нужно обеспечить сохранность данных даже после удаления контейнера.

**Шаг 1: Запуск контейнера с PostgreSQL**

```bash
docker run -d \
  --name my-postgres \
  -e POSTGRES_USER=admin \
  -e POSTGRES_PASSWORD=secretpassword \
  -e POSTGRES_DB=myappdb \
  -p 5432:5432 \
  postgres:16
```
*   `-e`: Установка переменных окружения.
*   `postgres:16`: Используем конкретную версию образа для стабильности.

**Шаг 2: Подключение к БД**

Можно использовать любую IDE (например, DataGrip) или командную строку (`docker exec`):
```bash
docker exec -it my-postgres psql -U admin -d myappdb
```

**Шаг 3: Тома (Volumes) для сохранения данных**

По умолчанию, все данные в контейнере удаляются вместе с ним. Том — это механизм для сохранения данных.

```bash
# Создаем том с именем 'postgres-data'
docker volume create postgres-data

# Запускаем PostgreSQL, монтируя том в директорию данных внутри контейнера
docker run -d \
  --name my-postgres \
  -e POSTGRES_PASSWORD=secretpassword \
  -v postgres-data:/var/lib/postgresql/data \ # <-- Ключевая строка!
  -p 5432:5432 \
  postgres:16
```
Теперь, даже если контейнер `my-postgres` будет удален, данные останутся в томе `postgres-data`. Новый контейнер, подключенный к этому тому, увидит все старые данные.

---

#### **5. Оркестрация многоконтейнерных приложений: Docker Compose**

Управлять несколькими контейнерами (приложение, БД, кэш) через отдельные команды `docker run` неудобно. **Docker Compose** — это инструмент для определения и запуска многоконтейнерных приложений с помощью одного YAML-файла.

**Создаем `docker-compose.yml`**

Поместите этот файл в корень вашего проекта (рядом с `.sln`).

```yaml
# Версия формата Compose файла (рекомендуется использовать современные версии без 'version')
services:
  # Сервис нашей базы данных
  postgres-db:
    image: postgres:16 # Используем официальный образ
    container_name: myapp-postgres
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: secretpassword
      POSTGRES_DB: myappdb
    volumes:
      - postgres-data:/var/lib/postgresql/data # Постоянное хранение данных
    ports:
      - "5432:5432" # Проброс порта для внешнего подключения (например, из IDE)
    # networks: (необязательно, Compose создаст сеть по умолчанию)
    #   - myapp-network

  # Сервис нашего .NET API
  web-api:
    build: . # Указываем путь к Dockerfile для сборки образа
    container_name: myapp-api
    environment:
      - ConnectionStrings__DefaultConnection=Host=postgres-db;Port=5432;Database=myappdb;Username=admin;Password=secretpassword
    depends_on:
      - postgres-db # Гарантирует, что postgres-db запустится первым
    ports:
      - "5000:8080"
    # networks:
    #   - myapp-network

# Определяем тома, которые будут использоваться сервисами
volumes:
  postgres-data:

# Определяем кастомные сети (необязательно)
# networks:
#   myapp-network:
#     driver: bridge
```

**Ключевые моменты:**
*   **`depends_on`:** Указывает, что `web-api` зависит от `postgres-db`. Compose запустит БД первой.
*   **Строка подключения:** Обратите внимание на `Host=postgres-db`. Внутри сети, созданной Compose, сервисы могут общаться друг с другом по имени сервиса (`postgres-db`), а не по IP-адресу.
*   **`build: .`:** Говорит Compose собрать образ из Dockerfile в текущей директории.

**Запуск приложения с Docker Compose**

```bash
# Запуск всех сервисов в фоновом режиме
docker-compose up -d

# Просмотр логов всех сервисов
docker-compose logs -f

# Остановка и удаление всех контейнеров, сетей (но НЕ томов!)
docker-compose down

# Остановка и удаление ВСЕГО, включая тома (ОСТОРОЖНО! Данные будут утеряны)
docker-compose down -v
```

Теперь ваше полное приложение (API + БД) работает по одной команде!

---

### **6. Резюме**

*   **Docker** решает проблему "работает на моей машине" через изоляцию приложений в контейнерах.
*   **Dockerfile** — это рецепт для создания переносимого образа вашего приложения.
*   Для stateful-сервисов (как PostgreSQL) обязательно используйте **Тома (Volumes)** для сохранения данных.
*   **Docker Compose** — мощный инструмент для оркестрации нескольких связанных контейнеров, позволяющий описывать всю инфраструктуру в одном декларативном файле (`docker-compose.yml`).
*   В микросервисной архитектуре .NET эти знания являются фундаментальными для создания, тестирования и развертывания приложений.

---

### **7. Контрольные вопросы**

1.  Объясните разницу между образом Docker и контейнером.
2.  Каковы основные преимущества использования контейнеризации в процессе разработки и развертывания?
3.  Что делает инструкция `COPY --from=build` в многоэтапном Dockerfile и зачем это нужно?
4.  Почему важно использовать том (Volume) при запуске базы данных PostgreSQL в Docker? Что произойдет с данными, если запустить контейнер без тома и затем его удалить?
5.  Как в Docker Compose сервис `web-api` узнает, как подключиться к сервису `postgres-db`? (Подсказка: посмотрите на строку подключения).
6.  Какая команда Docker Compose используется для запуска всего приложения в фоновом режиме? А для его остановки?
7.  Представьте, что вам нужно добавить в ваш стек сервис кэширования (например, Redis). Как бы вы изменили файл `docker-compose.yml`?